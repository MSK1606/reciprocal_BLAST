{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schmelling,Nicolas \n",
      "last updated: 2017-01-03 \n",
      "\n",
      "CPython 3.5.2\n",
      "IPython 4.1.1\n",
      "\n",
      "biopython 1.66\n",
      "pandas 0.18.0\n"
     ]
    }
   ],
   "source": [
    "%watermark -a Schmelling,Nicolas -u -d -v -p biopython,pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Any comments and suggestions or questions?     \n",
    "Please feel free to contact me via [twitter](https://twitter.com/derschmelling) or [email](mailto:Nicolas.Schmelling@hhu.de).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Molecular Tool Set for a Circadian Clock in Cyanobacteria #\n",
    "\n",
    "__Background__     \n",
    "Circadian clocks are found in almost all organisms including photosynthetic Cyanobacteria, whereby large diversity exists within the protein components involved. In the model cyanobacterium _Synechococcus elongatus_ PCC 7942 circadian rhythms are driven by a unique KaiABC protein clock, which is embedded in a network of input and output factors. Homologous proteins to the KaiABC clock have been observed in Bacteria and Archaea, where evidence for circadian behavior in these domains is accumulating. However, interaction and function of non-cyanobacterial Kai-proteins as well as homologous input and output components remain mainly unclear.     \n",
    "__Result__     \n",
    "Using a universal BLAST analyses, we identified putative KaiC-based timing systems in organisms outside as well as variations within Cyanobacteria. A systematic analyses of publicly available microarray data elucidated interesting variations in circadian gene expression between different cyanobacterial strains, which might be correlated to the diversity of genome encoded clock components. Based on statistical analyses of co-occurrences of the clock components homologous to _Synechococcus elongatus_, we propose putative networks of reduced and fully functional clock systems. Further, we studied KaiC sequence conservation to determine functionally important regions of diverged KaiC homologs. Biochemical characterization of exemplary cyanobacterial KaiC proteins as well as homologs from two thermophilic Archaea demonstrated that kinase activity is always present. However, a KaiA-mediated phosphorylation is only detectable in KaiC1 orthologs.      \n",
    "__Conclusion__     \n",
    "Our analysis of 11,264 genomes clearly demonstrates that components of the _Synechococcus elongatus_ circadian clock are present in Bacteria and Archaea. However, all components are less abundant in other organisms than Cyanobacteria and KaiA, Pex, LdpA, and CdpA are only present in the latter. Thus, only reduced KaiBC-based or even simpler, solely KaiC-based timing systems might exist outside of the cyanobacterial phylum, which might be capable of driving diurnal oscillations.\n",
    "\n",
    "## Data Collection and Preprocessing ##\n",
    "\n",
    "This notebook is the first of five notebooks containing all of the code necessary to reproduce the data collection and analyses of the publication by [Schmelling et al., 2016](https://doi.org/10.1101/075291 ). Within this notebook are all instructions and code to repeat the data collection and the preprocessing. The final processed datasets are also available at [FigShare](https://figshare.com/authors/Nicolas_Schmelling/699391). \n",
    "\n",
    "### Downloading the RefSeq protein sequences from NCBI ###\n",
    "\n",
    "__Run bash script__"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bash download_all_complete_genomes.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLAST with Synechococcus protein sequence against custom RefSeq Database ###\n",
    "\n",
    "__Install docker__\n",
    "\n",
    "For more information on how to install docker on your system visit the docker [installation page](https://www.docker.com/products/docker)\n",
    "\n",
    "__Pull the BLAST docker container and run it__"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "docker pull simonalpha/ncbi-blast-docker\n",
    "docker run -it -v ~/db:/blast/db simonalpha/ncbi-blast-docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create custom BLAST database from downloaded sequences__"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cd db\n",
    "makeblastdb -in all_genomes.fasta -dbtype 'prot' -out all_genomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Run BLAST for selected Synechococcus and Synechocystis sequences__"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for f in seq/*.fasta\n",
    "do\n",
    "blastp -query \"$f\" -db all_genomes -out \"${f%.fasta}_blast.xml\" -evalue 0.00001 -word_size 3 -outfmt 5 -num_alignments 10000\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Move all Synechocystis sequences into the seq/syn directory__"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mkdir seq/syn\n",
    "\n",
    "for f in seq/kaiB1.fasta seq/kaiB2.fasta seq/kaiB3.fasta seq/kaiC1.fasta seq/kaiC2.fasta seq/kaiC3.fasta\n",
    "do\n",
    "mv $f seq/syn/$f\n",
    "done\n",
    "\n",
    "for f in seq/kaiB1_blast.xml seq/kaiB2_blast.xml seq/kaiB3_blast.xml seq/kaiC1_blast.xml seq/kaiC2_blast.xml seq/kaiC3_blast.xml\n",
    "do\n",
    "mv $f seq/syn/$f\n",
    "done\n",
    "\n",
    "exit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create FASTA from matches ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "from Bio.Blast import NCBIXML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The parse_hits() function will read the BLAST output XML file, \n",
    "extract the genome and protein id to further extract the protein record\n",
    "description and sequence from the genome FASTA file.\n",
    "'''\n",
    "\n",
    "def parse_hits(f):\n",
    "    result_handle = open(f)\n",
    "    blast_record = NCBIXML.read(result_handle)\n",
    "    \n",
    "    # Split file path to extract protein name and use the path\n",
    "    # and protein to create the new FASTA file\n",
    "    prot = f.split('/')[f.count('/')].split('_')[0]\n",
    "    new_fasta = open(f.split(prot)[0]+'%s_matches.fasta' %prot, 'w')\n",
    "    \n",
    "    # Count records\n",
    "    rec = 0\n",
    "\n",
    "    # Loop through the XML file\n",
    "    for alignment in blast_record.alignments:\n",
    "        \n",
    "        # Record genome and protein ID and incearse the count\n",
    "        genome = alignment.title.split(' ')[-1]\n",
    "        ref_no = alignment.title.split(' ',2)[1]\n",
    "        rec += 1\n",
    "        \n",
    "        # Open genome FASTA file and find the original sequence\n",
    "        # and description for the record and write it to the \n",
    "        # new FASTA file containing all matches\n",
    "        file = glob.glob('AllGenomes/%s*.fasta'%genome)\n",
    "        for seq_record in SeqIO.parse(file[0], 'fasta'):\n",
    "            if ref_no in seq_record.description:\n",
    "                new_fasta.write('>'+str(seq_record.description))\n",
    "                new_fasta.write('\\n')\n",
    "                new_fasta.write(str(seq_record.seq))\n",
    "                new_fasta.write('\\n')\n",
    "\n",
    "    result_handle.close()\n",
    "    new_fasta.close()\n",
    " \n",
    "    print(prot,'\\t',rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the above function for all Synechococcus proteins\n",
    "for file in glob.glob('db/seq/*.xml'):\n",
    "    parse_hits(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the above function for all Synechocystis proteins\n",
    "for file in glob.glob('db/seq/syn/*.xml'):\n",
    "    parse_hits(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Command line BLAST with matches against Synechococcus Database ###\n",
    "\n",
    "__Run BLAST docker container__"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "docker run -it -v ~/db:/blast/db simonalpha/ncbi-blast-docker\n",
    "cd db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create BLAST database for the reciprocal BLAST__"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "makeblastdb -in Synechococcus_protein.fasta -dbtype 'prot' -out Synechococcus\n",
    "makeblastdb -in Synechocystis_protein.fasta -dbtype 'prot' -out Synechocystis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Run BLAST for sequences. Use respective genome database__"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for f in seq/*_matches.fasta\n",
    "do\n",
    "blastp -query \"$f\" -db Synechococcus -out \"${f%_matches.fasta}_back_blast.xml\" -evalue 10 -word_size 3 -outfmt 5 -num_alignments 1\n",
    "done\n",
    "\n",
    "for f in seq/syn/*_matches.fasta\n",
    "do\n",
    "blastp -query \"$f\" -db Synechocystis -out \"${f%_matches.fasta}_back_blast.xml\" -evalue 10 -word_size 3 -outfmt 5 -num_alignments 1\n",
    "done\n",
    "\n",
    "exit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse hits ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The filter_hits() function will take the BLAST output XML file from the \n",
    "second run and extracts the genome id to furhter collect information about  \n",
    "the corresponding orgnism, taxonomy, and BLAST results. The function will \n",
    "only collect these information for proteins that match to the original query\n",
    "protein from Synechococcus or Synechocystis and store them into a CSV file.\n",
    "'''\n",
    "\n",
    "def filter_hits(blast_file,protein,organism):\n",
    "    \n",
    "    # Always tell NCBI who you are.\n",
    "    Entrez.email = 'schmelli@msu.edu'\n",
    "    \n",
    "    # Read the XML file, extract the genome id, store it into a list\n",
    "    # and remove the duplicates by converintg it into a set and back\n",
    "    # in to a list\n",
    "    result_handle = open(blast_file)\n",
    "    blast_records = NCBIXML.parse(result_handle)\n",
    "\n",
    "    ids = []\n",
    "\n",
    "    for blast_record in blast_records:\n",
    "        ids.append(blast_record.query.split(' ')[-1])\n",
    "        \n",
    "    result_handle.close()\n",
    "        \n",
    "    ids = list(set(ids))\n",
    "    \n",
    "    # Create a dictionary that stores in the end organism, taxid,\n",
    "    # taxonomy (fetched from NCBI), and the last curation date\n",
    "    # for each genome.\n",
    "    taxo_dict = {}\n",
    "            \n",
    "    for id in ids:\n",
    "        # Open genome assembly report file to extract organism name,\n",
    "        # curation date, and, tax id and use the taxid to fetch\n",
    "        # taxonomy information from NCBI.\n",
    "        file = glob.glob('All_Reports/%s*_assembly_report.txt' %id)\n",
    "        \n",
    "        f = open(file[0], 'r')\n",
    "        f_read = f.readlines()\n",
    "        f.close()\n",
    "        \n",
    "        values = []\n",
    "        \n",
    "        for line in f_read:\n",
    "            \n",
    "            if line.startswith('# Organism name:'): \n",
    "                org = re.sub('  +','',line)\n",
    "                values.append(org.split(':',1)[1][:-1])\n",
    "                values.append(org.split(':',1)[1].split(' ',1)[0])\n",
    "\n",
    "            elif line.startswith('# Taxid:'):\n",
    "                org = re.sub('  +','',line)\n",
    "\n",
    "                try:\n",
    "                    handle = Entrez.efetch(db='taxonomy',\n",
    "                                           id='txid%s[Organism]'\\\n",
    "                                           %org.split(':',1)[1][:-1])\n",
    "                    record = Entrez.read(handle)\n",
    "                    values.append(record[0]['Lineage'])\n",
    "                except KeyError:\n",
    "                    values.append('missing taxonomy')\n",
    "\n",
    "                values.append(org.split(':',1)[1][:-1])\n",
    "                \n",
    "            elif line.startswith('# Date'):\n",
    "                date = re.sub('  +','',line)\n",
    "                values.append(date.split(':',1)[1][:-1])\n",
    "\n",
    "        taxo_dict[id] = values\n",
    "\n",
    "    # Reread the XML file and create also a CSV file for storage\n",
    "    result_handle = open(blast_file)\n",
    "    blast_records = NCBIXML.parse(result_handle)\n",
    "\n",
    "    id_dict = {'kaiA':'WP_011377921.1', 'kaiB':'WP_011242647.1',\n",
    "               'kaiC':'WP_011242648.1', 'pex':'WP_011377679.1',\n",
    "               'ldpA':'WP_011377652.1', 'prkE':'WP_011243235.1',\n",
    "               'nhtA':'WP_011378346.1', 'ircA':'WP_011378436.1',\n",
    "               'cdpA':'WP_011378107.1', 'cikA':'WP_011243194.1',\n",
    "               'sasA':'WP_011378322.1', 'rpaA':'WP_011377437.1',\n",
    "               'rpaB':'WP_011378039.1', 'lalA':'WP_011242719.1',\n",
    "               'labA':'WP_011244514.1', 'crm':'WP_011243720.1',\n",
    "               'cpmA':'WP_011377895.1',\n",
    "               'kaiB1':'WP_010874242.1', 'kaiC1':'WP_010874243.1',\n",
    "               'kaiB2':'WP_010872548.1', 'kaiC2':'WP_010872549.1',\n",
    "               'kaiB3':'WP_041425845.1', 'kaiC3':'WP_010873229.1'\n",
    "                }\n",
    "\n",
    "    csv = open('data/%s.csv'%protein, 'w')\n",
    "    csv.write('name,genus,taxonomy,taxid,protein,protein_id,genome_id'\\\n",
    "              ',e_value,bitscore,identity,length,seq'\\\n",
    "              ',%s_prot_id,%s_id,date\\n'%(organism,organism))\n",
    "\n",
    "    rec = 0\n",
    "\n",
    "    # Parse through the XML by records and extract genome ID.\n",
    "    # First check if the protein ID is in the alignment title.\n",
    "    # If so continue to write information into the CSV file.\n",
    "    for blast_record in blast_records:\n",
    "        \n",
    "        genome = blast_record.query.split(' ')[-1]\n",
    "        alignment = blast_record.alignments[0]\n",
    "        hsp = alignment.hsps[0]\n",
    "        \n",
    "        if id_dict[protein] in alignment.title:\n",
    "        \n",
    "            # Write organisms name, genus name, taxonomy, and tax id\n",
    "            csv.write(str(taxo_dict[genome][0]).replace(',',';')+',')\n",
    "            csv.write(str(taxo_dict[genome][1]).replace(',',';')+',')\n",
    "            csv.write(str(taxo_dict[genome][2]).replace(',',';')+',')\n",
    "            csv.write(str(taxo_dict[genome][3]).replace(',',';')+',')\n",
    "\n",
    "            rec += 1\n",
    "            \n",
    "            # Write protein name, protein id, and genome id\n",
    "            csv.write(str(blast_record.query.split(' ',1)[1]\\\n",
    "                          .split(genome)[0]).replace(',',';')+',')\n",
    "            csv.write(str(blast_record.query.split(' ',1)[0])\\\n",
    "                          .replace(',',';')+',')\n",
    "            csv.write(str(blast_record.query.split(' ')[-1]\\\n",
    "                          .replace(',',';'))+',')\n",
    "            \n",
    "            # Write BLAST result statistics, like e value, bitscore,\n",
    "            # and indentity, as well as protein sequence length\n",
    "            csv.write(str(hsp.expect).replace(',',';')+',')\n",
    "            csv.write(str(hsp.score).replace(',',';')+',')\n",
    "            csv.write(str(hsp.identities/float(len(hsp.match))*100)\\\n",
    "                          .replace(',',';')+',')\n",
    "\n",
    "            csv.write(str(blast_record.query_length).replace(',',';')+',')\n",
    "            \n",
    "            # Look for protein sequence in the genome FASTA file\n",
    "            # and write protein sequence into CSV file\n",
    "            genome_file = glob.glob('AllGenomes/%s*.fasta' %genome)\n",
    "            \n",
    "            for seq_record in SeqIO.parse(genome_file[0], 'fasta'):\n",
    "                if blast_record.query.split(' ',1)[0] in seq_record.description:\n",
    "                    csv.write(str(seq_record.seq).replace(',',';')+',')\n",
    "                    break\n",
    "            \n",
    "            # Last write Synechococcus/Synechocystis protein id and genome id\n",
    "            # as well as curation date\n",
    "            csv.write(str(id_dict[protein]).replace(',',';')+',')\n",
    "            csv.write(str(alignment.title.split(' ')[-1]).replace(',',';')+',')\n",
    "\n",
    "            csv.write(str(taxo_dict[genome][4]).replace(',',';')+'\\n')\n",
    "\n",
    "    result_handle.close()\n",
    "    csv.close()\n",
    "    print(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run above function for all Synechococcus proteins\n",
    "for prot in ['kaiA','kaiB','kaiC','pex','ldpA','prkE','nhtA','ircA','cdpA','cikA',\n",
    "             'sasA','rpaA','rpaB','lalA','labA','crm','cpmA']:\n",
    "    filter_hits('db/seq/%s_back_blast.xml'%prot,prot,'synechococcus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run above function for all Synechocystis proteins\n",
    "for prot in ['kaiB1','kaiC1','kaiB2','kaiC2','kaiB3','kaiC3']:\n",
    "    filter_hits('db/seq/syn/%s_back_blast.xml'%prot,prot,'synechocystis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Next ###\n",
    "\n",
    "+ [Distribution of circadian clock protein](2_KaiABC_BLAST_Heatmap.ipynb)\n",
    "+ [Length distribution of KaiA, KaiB, KaiC](3_KaiABC_BLAST_Scatterplot.ipynb)\n",
    "+ [Co-occurence of circadian clock proteins in cyanobacteria](4_KaiABC_BLAST_FisherTest.ipynb)\n",
    "+ [Additional Analyses](5_KaiABC_BLAST_Other.ipynb)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
